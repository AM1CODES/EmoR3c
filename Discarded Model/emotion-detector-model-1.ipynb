{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/fer2013/train\" #passing the path with training images\ntest_dir = \"../input/fer2013/test\"   #passing the path with testing images","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 48 #original size of the image","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nData Augmentation\n--------------------------\nrotation_range = rotates the image with the amount of degrees we provide\nwidth_shift_range = shifts the image randomly to the right or left along the width of the image\nheight_shift range = shifts image randomly to up or below along the height of the image\nhorizontal_flip = flips the image horizontally\nrescale = to scale down the pizel values in our image between 0 and 1\nzoom_range = applies random zoom to our object\nvalidation_split = reserves some images to be used for validation purpose\n\"\"\"\n\ntrain_datagen = ImageDataGenerator(rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1./255,\n                                         zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = ImageDataGenerator(rescale = 1./255,\n                                         validation_split = 0.2)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nApplying data augmentation to the images as we read \nthem from their respectivve directories\n\"\"\"\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (img_size,img_size),\n                                                    batch_size = 64,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (img_size,img_size),\n                                                              batch_size = 64,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","execution_count":5,"outputs":[{"output_type":"stream","text":"Found 22968 images belonging to 7 classes.\nFound 1432 images belonging to 7 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nModeling\n\"\"\"\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape = (img_size,img_size,1)))\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Flatten())\nmodel.add(Dense(units = 128,activation = 'relu',kernel_initializer='normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units = 64,activation = 'relu',kernel_initializer='normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units = 64,activation = 'relu',kernel_initializer='normal'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(7,activation = 'softmax'))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\noptimizer = Adam(lr = 0.001)\nmodel.compile(loss = \"categorical_crossentropy\",optimizer = optimizer,metrics = ['accuracy'])\nepochs = 50\nbatch_size = 64","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":27,"outputs":[{"output_type":"stream","text":"Model: \"sequential_4\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_16 (Conv2D)           (None, 48, 48, 64)        640       \n_________________________________________________________________\nmax_pooling2d_16 (MaxPooling (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, 24, 24, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_17 (MaxPooling (None, 12, 12, 64)        0         \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, 12, 12, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_18 (MaxPooling (None, 6, 6, 64)          0         \n_________________________________________________________________\nconv2d_19 (Conv2D)           (None, 6, 6, 64)          36928     \n_________________________________________________________________\nmax_pooling2d_19 (MaxPooling (None, 3, 3, 64)          0         \n_________________________________________________________________\nflatten_4 (Flatten)          (None, 576)               0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 128)               73856     \n_________________________________________________________________\ndropout_11 (Dropout)         (None, 128)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndropout_12 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndropout_13 (Dropout)         (None, 64)                0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 7)                 455       \n=================================================================\nTotal params: 198,151\nTrainable params: 198,151\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x = train_generator,steps_per_epoch = 22968//64,epochs = epochs,validation_data = validation_generator,validation_steps = 1432//64)","execution_count":28,"outputs":[{"output_type":"stream","text":"Epoch 1/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.8054 - accuracy: 0.2465 - val_loss: 1.7809 - val_accuracy: 0.2578\nEpoch 2/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.7843 - accuracy: 0.2527 - val_loss: 1.7860 - val_accuracy: 0.2543\nEpoch 3/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.7805 - accuracy: 0.2562 - val_loss: 1.7693 - val_accuracy: 0.2699\nEpoch 4/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.7616 - accuracy: 0.2656 - val_loss: 1.7586 - val_accuracy: 0.2855\nEpoch 5/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.7519 - accuracy: 0.2728 - val_loss: 1.7405 - val_accuracy: 0.2756\nEpoch 6/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.7416 - accuracy: 0.2788 - val_loss: 1.7539 - val_accuracy: 0.2884\nEpoch 7/50\n358/358 [==============================] - 27s 77ms/step - loss: 1.7144 - accuracy: 0.3027 - val_loss: 1.7659 - val_accuracy: 0.2834\nEpoch 8/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.6946 - accuracy: 0.3091 - val_loss: 1.6582 - val_accuracy: 0.3338\nEpoch 9/50\n358/358 [==============================] - 27s 77ms/step - loss: 1.6788 - accuracy: 0.3188 - val_loss: 1.6467 - val_accuracy: 0.3310\nEpoch 10/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.6582 - accuracy: 0.3296 - val_loss: 1.6162 - val_accuracy: 0.3523\nEpoch 11/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.6444 - accuracy: 0.3394 - val_loss: 1.6119 - val_accuracy: 0.3743\nEpoch 12/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.6231 - accuracy: 0.3523 - val_loss: 1.5743 - val_accuracy: 0.3928\nEpoch 13/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.5980 - accuracy: 0.3602 - val_loss: 1.5526 - val_accuracy: 0.3970\nEpoch 14/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.5900 - accuracy: 0.3709 - val_loss: 1.5748 - val_accuracy: 0.3707\nEpoch 15/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.5783 - accuracy: 0.3793 - val_loss: 1.5394 - val_accuracy: 0.3963\nEpoch 16/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.5653 - accuracy: 0.3919 - val_loss: 1.5048 - val_accuracy: 0.4197\nEpoch 17/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.5525 - accuracy: 0.3868 - val_loss: 1.4723 - val_accuracy: 0.4347\nEpoch 18/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.5320 - accuracy: 0.4062 - val_loss: 1.4791 - val_accuracy: 0.4261\nEpoch 19/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.5286 - accuracy: 0.4057 - val_loss: 1.4585 - val_accuracy: 0.4503\nEpoch 20/50\n358/358 [==============================] - 27s 77ms/step - loss: 1.5260 - accuracy: 0.4044 - val_loss: 1.4601 - val_accuracy: 0.4382\nEpoch 21/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.5192 - accuracy: 0.4102 - val_loss: 1.4430 - val_accuracy: 0.4361\nEpoch 22/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.5174 - accuracy: 0.4074 - val_loss: 1.4673 - val_accuracy: 0.4212\nEpoch 23/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.4964 - accuracy: 0.4194 - val_loss: 1.4737 - val_accuracy: 0.4233\nEpoch 24/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4853 - accuracy: 0.4275 - val_loss: 1.5483 - val_accuracy: 0.3935\nEpoch 25/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4876 - accuracy: 0.4221 - val_loss: 1.5051 - val_accuracy: 0.4169\nEpoch 26/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.4885 - accuracy: 0.4233 - val_loss: 1.4784 - val_accuracy: 0.4261\nEpoch 27/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4678 - accuracy: 0.4339 - val_loss: 1.4279 - val_accuracy: 0.4439\nEpoch 28/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4782 - accuracy: 0.4282 - val_loss: 1.4505 - val_accuracy: 0.4354\nEpoch 29/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.4792 - accuracy: 0.4300 - val_loss: 1.4121 - val_accuracy: 0.4638\nEpoch 30/50\n358/358 [==============================] - 29s 80ms/step - loss: 1.4599 - accuracy: 0.4363 - val_loss: 1.4098 - val_accuracy: 0.4581\nEpoch 31/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4494 - accuracy: 0.4433 - val_loss: 1.3975 - val_accuracy: 0.4751\nEpoch 32/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.4478 - accuracy: 0.4396 - val_loss: 1.4381 - val_accuracy: 0.4474\nEpoch 33/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.4310 - accuracy: 0.4487 - val_loss: 1.3937 - val_accuracy: 0.4709\nEpoch 34/50\n358/358 [==============================] - 28s 79ms/step - loss: 1.4362 - accuracy: 0.4475 - val_loss: 1.4013 - val_accuracy: 0.4581\nEpoch 35/50\n358/358 [==============================] - 28s 79ms/step - loss: 1.4451 - accuracy: 0.4404 - val_loss: 1.3609 - val_accuracy: 0.4744\nEpoch 36/50\n358/358 [==============================] - 28s 79ms/step - loss: 1.4201 - accuracy: 0.4499 - val_loss: 1.3841 - val_accuracy: 0.4716\nEpoch 37/50\n358/358 [==============================] - 28s 78ms/step - loss: 1.4306 - accuracy: 0.4455 - val_loss: 1.3542 - val_accuracy: 0.4759\nEpoch 38/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4162 - accuracy: 0.4482 - val_loss: 1.3511 - val_accuracy: 0.4822\nEpoch 39/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.4269 - accuracy: 0.4498 - val_loss: 1.4205 - val_accuracy: 0.4446\nEpoch 40/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4262 - accuracy: 0.4476 - val_loss: 1.3775 - val_accuracy: 0.4780\nEpoch 41/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.4193 - accuracy: 0.4547 - val_loss: 1.3397 - val_accuracy: 0.4972\nEpoch 42/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.4211 - accuracy: 0.4509 - val_loss: 1.3388 - val_accuracy: 0.5007\nEpoch 43/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.4096 - accuracy: 0.4540 - val_loss: 1.3447 - val_accuracy: 0.4744\nEpoch 44/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.4006 - accuracy: 0.4604 - val_loss: 1.3650 - val_accuracy: 0.4787\nEpoch 45/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.4157 - accuracy: 0.4570 - val_loss: 1.3557 - val_accuracy: 0.4744\nEpoch 46/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.4087 - accuracy: 0.4589 - val_loss: 1.3426 - val_accuracy: 0.4886\nEpoch 47/50\n358/358 [==============================] - 27s 76ms/step - loss: 1.4040 - accuracy: 0.4633 - val_loss: 1.3110 - val_accuracy: 0.4936\nEpoch 48/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.4007 - accuracy: 0.4641 - val_loss: 1.3377 - val_accuracy: 0.4929\nEpoch 49/50\n358/358 [==============================] - 27s 75ms/step - loss: 1.3920 - accuracy: 0.4658 - val_loss: 1.3323 - val_accuracy: 0.4936\nEpoch 50/50\n358/358 [==============================] - 28s 77ms/step - loss: 1.3935 - accuracy: 0.4632 - val_loss: 1.2908 - val_accuracy: 0.5170\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}