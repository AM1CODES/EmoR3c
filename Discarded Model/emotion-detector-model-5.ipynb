{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPool2D, Flatten,Dense,Dropout,BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom tensorflow.keras.applications import VGG16, InceptionResNetV2","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = \"../input/fer2013/train\" #passing the path with training images\ntest_dir = \"../input/fer2013/test\"   #passing the path with testing images","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 48 #original size of the image","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nData Augmentation\n--------------------------\nrotation_range = rotates the image with the amount of degrees we provide\nwidth_shift_range = shifts the image randomly to the right or left along the width of the image\nheight_shift range = shifts image randomly to up or below along the height of the image\nhorizontal_flip = flips the image horizontally\nrescale = to scale down the pizel values in our image between 0 and 1\nzoom_range = applies random zoom to our object\nvalidation_split = reserves some images to be used for validation purpose\n\"\"\"\n\ntrain_datagen = ImageDataGenerator(rotation_range = 180,\n                                         width_shift_range = 0.1,\n                                         height_shift_range = 0.1,\n                                         horizontal_flip = True,\n                                         rescale = 1./255,\n                                         zoom_range = 0.2,\n                                         validation_split = 0.2\n                                        )\nvalidation_datagen = ImageDataGenerator(rescale = 1./255,\n                                         validation_split = 0.2)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nApplying data augmentation to the images as we read \nthem from their respectivve directories\n\"\"\"\ntrain_generator = train_datagen.flow_from_directory(directory = train_dir,\n                                                    target_size = (img_size,img_size),\n                                                    batch_size = 64,\n                                                    color_mode = \"grayscale\",\n                                                    class_mode = \"categorical\",\n                                                    subset = \"training\"\n                                                   )\nvalidation_generator = validation_datagen.flow_from_directory( directory = test_dir,\n                                                              target_size = (img_size,img_size),\n                                                              batch_size = 64,\n                                                              color_mode = \"grayscale\",\n                                                              class_mode = \"categorical\",\n                                                              subset = \"validation\"\n                                                             )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nModeling\n\"\"\"\n\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32,kernel_size = (3,3),padding = 'same',activation = 'relu',input_shape = (img_size,img_size,1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\n\nmodel.add(Conv2D(filters = 64,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\n\nmodel.add(Conv2D(filters = 128,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters = 512,kernel_size = (3,3),padding = 'same',activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size = 2,strides = 2))\n\nmodel.add(Flatten())\n#model.add(Dense(units = 128,activation = 'relu',kernel_initializer='normal'))\n#model.add(BatchNormalization())\n#model.add(Dropout(0.25))\nmodel.add(Dense(units = 256,activation = 'relu',kernel_initializer='normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(units = 512,activation = 'relu',kernel_initializer='normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\nmodel.add(Dense(7,activation = 'softmax'))","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'Sequential' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-1e3eabb4a999>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\noptimizer = Adam(lr = 0.001)\nmodel.compile(loss = \"categorical_crossentropy\",optimizer = optimizer,metrics = ['accuracy'])\nepochs = 70\nbatch_size = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x = train_generator,steps_per_epoch = 22968//64,epochs = epochs,validation_data = validation_generator,validation_steps = 1432//64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nfig.set_size_inches(12,4)\n\nax[0].plot(history.history['accuracy'])\nax[0].plot(history.history['val_accuracy'])\nax[0].set_title('Training Accuracy vs Validation Accuracy')\nax[0].set_ylabel('Accuracy')\nax[0].set_xlabel('Epoch')\nax[0].legend(['Train', 'Validation'], loc='upper left')\n\nax[1].plot(history.history['loss'])\nax[1].plot(history.history['val_loss'])\nax[1].set_title('Training Loss vs Validation Loss')\nax[1].set_ylabel('Loss')\nax[1].set_xlabel('Epoch')\nax[1].legend(['Train', 'Validation'], loc='upper left')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}